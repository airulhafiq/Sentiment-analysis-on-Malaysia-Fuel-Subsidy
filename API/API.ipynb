{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API for DASHBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Specify the directory of your saved model\n",
    "saved_model_path = \"bert_sentiment_model_adam44\"\n",
    "\n",
    "# Load the model from the saved directory\n",
    "model = BertForSequenceClassification.from_pretrained(saved_model_path)\n",
    "print(\"Model loaded successfully!\")\n",
    "#C:/Users/airul hafiq/Desktop/DataPreprocessing/DataPreprocessing/Model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPreprocessing\\.venv\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPreprocessing\\API\\test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uvicorn DataPreprocessing.API.app:app --reload --port 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -X \"POST\" \"http://127.0.0.1:8000/predict\" -H \"Content-Type: application/json\" -d \"{\\\"comment\\\": \\\"He just read book\\\"}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -X \"POST\" \"http://127.0.0.1:8000/predict\" -H \"Content-Type: application/json\" -d \"{\\\"comment\\\": \\\"He just read book\\\"}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qrcode\n",
    "\n",
    "public_url = \"https://caring-stag-happy.ngrok-free.app \"  # Replace with your Ngrok URL\n",
    "qr = qrcode.make(public_url)\n",
    "qr.save(\"fastapi_qr.png\")\n",
    "\n",
    "print(\"QR code saved as fastapi_qr.png. Share it for public testing!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrok http 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # Specify the output file path\n",
    "# output_path = \"bert_sentiment_model_adam44.pt\"\n",
    "\n",
    "# # Save the model state dictionary in PyTorch format\n",
    "# torch.save(model.state_dict(), output_path)\n",
    "# print(f\"Model saved in PyTorch format to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flask API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_path = \"bert_sentiment_model_adam44\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict_sentiment():\n",
    "    try:\n",
    "        data = request.json\n",
    "        if 'comment' not in data:\n",
    "            return jsonify({\"error\": \"No comment provided\"}), 400\n",
    "\n",
    "        comment = data['comment']\n",
    "\n",
    "        # Preprocess input\n",
    "        inputs = tokenizer(comment, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        sentiment = torch.argmax(probabilities).item()\n",
    "\n",
    "        sentiment_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "\n",
    "        return jsonify({\"sentiment\": sentiment_map[sentiment]})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return jsonify({\"message\": \"Server is running!\"})\n",
    "\n",
    "def run_app():\n",
    "    app.run(host='0.0.0.0', port=5000, debug=True, use_reloader=False)\n",
    "\n",
    "# Start Flask server in a background thread\n",
    "thread = Thread(target=run_app)\n",
    "thread.daemon = True\n",
    "thread.start()\n",
    "\n",
    "# Notebook execution continues here\n",
    "time.sleep(2)  # Wait for the server to start\n",
    "print(\"Flask server is running in the background!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:5000/predict\"\n",
    "payload = {\"comment\": \"This is a great product!\"}\n",
    "response = requests.post(url, json=payload)\n",
    "print(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
